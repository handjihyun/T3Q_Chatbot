{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!python --version"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cwq7bXpKTmnS","executionInfo":{"status":"ok","timestamp":1685597094226,"user_tz":-540,"elapsed":11,"user":{"displayName":"이소정","userId":"01839645290221900498"}},"outputId":"be7aec47-bdea-432e-b90d-7ab950e5628a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Python 3.6.9\n"]}]},{"cell_type":"code","source":["!wget https://www.python.org/ftp/python/3.10.1/Python-3.10.1tgz\n","!tar xvfz Python-3.10.1tgz\n","!Python-3.10.1/configure\n","!make\n","!sudo make install"],"metadata":{"id":"sTdF7stsTr8n"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!python --version"],"metadata":{"id":"ptamd7m_Uq5c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install --upgrade mxnet>=1.6.0\n","!pip install gluonnlp==0.9.1\n","!pip install pandas tqdm\n","!pip install sentencepiece\n","!pip install transformers\n","!pip install torch"],"metadata":{"id":"meeZqeB8YVjc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install onnxruntime==1.3.0"],"metadata":{"id":"QeK4hW29YjJ6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install git+https://git@github.com/SKTBrain/KoBERT.git@master"],"metadata":{"id":"PEQ9bK6hYWBZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# !pip install 'git+https://github.com/SKTBrain/KoBERT.git#egg=kobert_tokenizer&subdirectory=kobert_hf'"],"metadata":{"id":"xWrgivyvnfnV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from tqdm import tqdm, tqdm_notebook\n","\n","import torch\n","from torch import nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","from sklearn.model_selection import train_test_split\n","\n","import mxnet\n","import gluonnlp as nlp"],"metadata":{"id":"b_8VcugMnwXW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#transformers \n","from transformers import AdamW\n","from transformers.optimization import get_cosine_schedule_with_warmup"],"metadata":{"id":"22dcnfaXn4DS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#kobert\n","from kobert_tokenizer import KoBERTTokenizer\n","from transformers import BertModel"],"metadata":{"id":"k7kOMG6kn7kz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","device"],"metadata":{"id":"K58Te0WnMUCf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"SxmBRHXn6yLr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Chatbot_Data = pd.read_csv('/content/drive/MyDrive/T3Q-자연어/CHATBOT/new_data.csv', index_col = 0)\n","Chatbot_Data"],"metadata":{"id":"8PvOzGRooPOq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Chatbot_Data[['label', 'raw_label']].nunique()"],"metadata":{"id":"FyE04apY6OGu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Emotion = Chatbot_Data[['label', 'raw_label']].drop_duplicates().sort_values('label')\n","Emotion_data = {label: emotion for label, emotion in zip(Emotion['label'], Emotion['raw_label'])}\n","\n","Emotion_data"],"metadata":{"id":"ReNFUCw_7lGK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset_train, dataset_test = train_test_split(Chatbot_Data, \n","                                               test_size = 0.4, \n","                                               random_state = 0, \n","                                               stratify = Chatbot_Data.label)"],"metadata":{"id":"QTr7GG3D8U-a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset_val, dataset_test = train_test_split(dataset_test, \n","                                               test_size = 0.5, \n","                                               random_state = 0, \n","                                               stratify = dataset_test.label)"],"metadata":{"id":"w34y22R3Dt4X"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset_train.raw_label.value_counts()"],"metadata":{"id":"KpSk5JQBDt2H"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset_val.raw_label.value_counts()"],"metadata":{"id":"qHmGkdNZDh75"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset_test.raw_label.value_counts()"],"metadata":{"id":"gGl0rOh3DqtX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### KoBERT 입력 데이터 만들기"],"metadata":{"id":"g37Qz99fFJ5q"}},{"cell_type":"code","source":["import kobert_tokenizer\n","MODEL_NAME = 'skt/kobert-base-v1'\n","bert_model = BertModel.from_pretrained(MODEL_NAME, return_dict=True)\n","kobert_tokenizer = KoBERTTokenizer.from_pretrained(MODEL_NAME)\n"],"metadata":{"id":"OyAw494zn8yL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["result = kobert_tokenizer.tokenize('너는 내년 대선 때 투표할 수 있어?')\n","print(result)\n","print([kobert_tokenizer.encode(token) for token in result])"],"metadata":{"id":"-mn10AQpYVhi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["kobert_tokenizer.encode(result)"],"metadata":{"id":"aq_Jv8P5Y-g7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["kobert_vocab = kobert_tokenizer.get_vocab()\n","kobert_vocab"],"metadata":{"id":"mdC2Pj_mYrtA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for i in dataset_train.Q:\n","    vocab = kobert_tokenizer(i + '13').input_ids\n","    vocab.append(13)\n","    print(vocab)\n","    break"],"metadata":{"id":"9HhPQ8tC-Etq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for i in dataset_train:\n","    print(i[0])\n","    break"],"metadata":{"id":"u9boVqhCR6T-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for i in dataset_train.label:\n","    print(np.int32(i))"],"metadata":{"id":"Q_k2ZVrxAf62"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class BERTDataset(Dataset):\n","    def __init__(self, \n","                dataset, tokenizer):\n","        self.dataset = dataset\n","        self.tokenizer = tokenizer\n","        self.sentences =  [self.tokenizer(i[0] + str(i[2])).input_ids for i in self.dataset]\n","        self.labels = [np.int32(i) for i in self.label]\n","\n","    def __len__(self):\n","        return len(self.label)\n","\n","    def __getitem__(self, index:int):\n","        return self.sentences[index]"],"metadata":{"id":"lpHL9QKdFDXV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["bert_train = BERTDataset(dataset_train, kobert_tokenizer)"],"metadata":{"id":"jr31459xkeSZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["bert_train[1]"],"metadata":{"id":"8QiJgkjU6EPp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["bert_dataloader = torch.utils.data.DataLoader(bert_train, batch_size=32, shuffle = False, \n","                                              drop_last = True)\n","for i in bert_dataloader:\n","    print(i)\n","    break\n"],"metadata":{"id":"gm5VxewIeT2j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset_train"],"metadata":{"id":"eYCwB8J1cfIk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for i in dataset_train.Q:\n","    print(i)"],"metadata":{"id":"NYcaYJbQZJgt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## setting parameters\n","\n","max_len = 64\n","batch_size = 32\n","warmup_ratio = 0.1\n","num_epochs = 5\n","max_grad_norm = 1\n","log_interval = 200\n","learning_rate = 5e-5"],"metadata":{"id":"0O7MHFcEuNcf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tok = nlp.data.BERTSPTokenizer(tokenizer, lower=False)\n"],"metadata":{"id":"BG5_bu9w0joO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"QD2XOR_I49jK"},"execution_count":null,"outputs":[]}]}